---
layout:     post
title:      数据倾斜优化
subtitle:   数据倾斜优化
date:       2018-10-10
author:     danfeng
header-img: img/post-bg-ios10.jpg
catalog: 	 true
tags:
    - SPARK
    - BIGDATA
---       

   &emsp;在大数据处理时候，基于MapReduce的思想，通常是分而治之，将数据分割，然后并行处理，这样每一个executor只需要处理自己所负责的那一部分数据即可，这样各个
executor就可以同处理一小部分工作，加快大数据处理，这一切看上去很美好，但是不可 避免的存在极端情况下，数据在各个executor上分布不均，导致个别executor
数据远大于其他节点，导致executor负载不均衡，从而拖慢整体处理进度，严重情况下很可能平时几分钟就可以完成的任务导致最终几个小时也没有出结果甚至OOM错误。
因此数据倾斜的处理很关键，。
   <br> &emsp;&emsp;RDD在计算的时候，每个分区都会起一个task，所以rdd的分区数目决定了总的的task数目。申请的计算节点（Executor）数目和每个计算节点核数，决定了你同一时刻可以并行执行的task。比如的RDD有100个分区，那么计算的时候就会生成100个task，你的资源配置为10个计算节点，每个两2个核，同一时刻可以并行的task数目为20，计算这个RDD就需要5个轮次。如果计算资源不变，你有101个task的话，就需要6个轮次，在最后一轮中，只有一个task在执行，其余核都在空转。如果资源不变，你的RDD只有2个分区，那么同一时刻只有2个task运行，其余18个核空转，造成资源浪费。这就是在spark调优中，增大RDD分区数目，增大任务并行度的做法。

